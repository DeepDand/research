2018-03-30 23:23:04.839458: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-03-30 23:23:04.839613: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-03-30 23:23:04.839647: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-03-30 23:23:04.839674: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-03-30 23:23:04.839701: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-03-30 23:23:05.657136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: 
name: Tesla P100-SXM2-16GB
major: 6 minor: 0 memoryClockRate (GHz) 1.4805
pciBusID 0000:08:00.0
Total memory: 15.89GiB
Free memory: 15.33GiB
2018-03-30 23:23:05.657300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 
2018-03-30 23:23:05.657338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y 
2018-03-30 23:23:05.657384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:08:00.0)
['S01']
[]
[]
Loading images  ../dataset/*.jpeg ['S01']
Number of images: 6200
Number of rows: 256
Number of cols: 256
Dataset array size:  (6200, 256, 256, 1)
(3100, 256, 256, 1)
(1550, 256, 256, 1)
(1550, 256, 256, 1)



| Training Step | Cross Entropy |  Layer  |   Epoch  |
|---------------|---------------|---------|----------|
|             0 |    54138.8281 | Layer 1 | Epoch 1  |
|          5000 |    20867.6211 | Layer 1 | Epoch 2  |
|         10000 |    19611.1738 | Layer 1 | Epoch 4  |
|         15000 |    18525.6172 | Layer 1 | Epoch 5  |
|         20000 |    18205.7969 | Layer 1 | Epoch 7  |
|         25000 |    18116.6387 | Layer 1 | Epoch 9  |
|         30000 |    17672.3438 | Layer 1 | Epoch 10  |
|         35000 |    17253.5117 | Layer 1 | Epoch 12  |
|         40000 |    17122.6133 | Layer 1 | Epoch 13  |
|         45000 |    16628.9180 | Layer 1 | Epoch 15  |
|         50000 |    16548.3477 | Layer 1 | Epoch 17  |
|         55000 |    16460.2871 | Layer 1 | Epoch 18  |
|         60000 |    16351.2480 | Layer 1 | Epoch 20  |
|         65000 |    16227.6982 | Layer 1 | Epoch 21  |
|         70000 |    16082.3242 | Layer 1 | Epoch 23  |
|         75000 |    16076.2354 | Layer 1 | Epoch 25  |
|         80000 |    16169.6152 | Layer 1 | Epoch 26  |
|         85000 |    16047.4297 | Layer 1 | Epoch 28  |
|         90000 |    16106.0430 | Layer 1 | Epoch 30  |
|         95000 |    16187.1289 | Layer 1 | Epoch 31  |
|        100000 |    16375.8955 | Layer 1 | Epoch 33  |
|        105000 |    16327.7852 | Layer 1 | Epoch 34  |
|        110000 |    16080.1133 | Layer 1 | Epoch 36  |
|        115000 |    15905.9072 | Layer 1 | Epoch 38  |
|        120000 |    15783.5518 | Layer 1 | Epoch 39  |
|        125000 |    15842.1836 | Layer 1 | Epoch 41  |
|        130000 |    15532.1143 | Layer 1 | Epoch 42  |
|        135000 |    15707.0781 | Layer 1 | Epoch 44  |
|        140000 |    15727.9316 | Layer 1 | Epoch 46  |
|        145000 |    16168.9902 | Layer 1 | Epoch 47  |
|        150000 |    15939.0293 | Layer 1 | Epoch 49  |



| Training Step | Cross Entropy |  Layer  |   Epoch  |
|---------------|---------------|---------|----------|
|             0 |     5695.9102 | Layer 2 | Epoch 1  |
|          5000 |     5452.7241 | Layer 2 | Epoch 2  |
|         10000 |     5325.9312 | Layer 2 | Epoch 4  |
|         15000 |     5255.6738 | Layer 2 | Epoch 5  |
|         20000 |     5158.1289 | Layer 2 | Epoch 7  |
|         25000 |     5082.3628 | Layer 2 | Epoch 9  |
|         30000 |     5065.4688 | Layer 2 | Epoch 10  |
|         35000 |     5040.1602 | Layer 2 | Epoch 12  |
|         40000 |     4997.9238 | Layer 2 | Epoch 13  |
|         45000 |     4943.5391 | Layer 2 | Epoch 15  |
|         50000 |     4952.2344 | Layer 2 | Epoch 17  |
|         55000 |     4936.0869 | Layer 2 | Epoch 18  |
|         60000 |     4847.8696 | Layer 2 | Epoch 20  |
|         65000 |     4846.8184 | Layer 2 | Epoch 21  |
|         70000 |     4860.1104 | Layer 2 | Epoch 23  |
|         75000 |     4838.8379 | Layer 2 | Epoch 25  |
|         80000 |     4836.5923 | Layer 2 | Epoch 26  |
|         85000 |     4850.7793 | Layer 2 | Epoch 28  |
|         90000 |     4825.8730 | Layer 2 | Epoch 30  |
|         95000 |     4845.2339 | Layer 2 | Epoch 31  |
|        100000 |     4788.3560 | Layer 2 | Epoch 33  |
|        105000 |     4733.4038 | Layer 2 | Epoch 34  |
|        110000 |     4730.2754 | Layer 2 | Epoch 36  |
|        115000 |     4733.2974 | Layer 2 | Epoch 38  |
|        120000 |     4796.0713 | Layer 2 | Epoch 39  |
|        125000 |     4724.3027 | Layer 2 | Epoch 41  |
|        130000 |     4766.2891 | Layer 2 | Epoch 42  |
|        135000 |     4762.0459 | Layer 2 | Epoch 44  |
|        140000 |     4641.4834 | Layer 2 | Epoch 46  |
|        145000 |     4735.0342 | Layer 2 | Epoch 47  |
|        150000 |     4737.1172 | Layer 2 | Epoch 49  |
Loading images  ../dataset/*.jpeg ['S01']
Number of images: 6200
Number of rows: 256
Number of cols: 256
Dataset array size:  (6200, 256, 256, 1)
Extracting labels from data in  ../dataset/*.jpeg ['S01']
(3100, 256, 256, 1)
(3100,)
(1550, 256, 256, 1)
(1550,)
(1550, 256, 256, 1)
(1550,)
Tensor("ExpandDims_1:0", shape=(250, 1), dtype=int32)
Tensor("ExpandDims:0", shape=(250, 1), dtype=int32)
Tensor("Size:0", shape=(), dtype=int32)
31
Step 0: loss = 3.51 (0.193 sec)
  Num examples: 3000  Num correct: 1679  Error @ 1: 0.4403
  Num examples: 1500  Num correct: 804  Error @ 1: 0.4640
  Num examples: 1500  Num correct: 767  Error @ 1: 0.4887
Step 5000: loss = 2.86 (0.128 sec)
  Num examples: 3000  Num correct: 2134  Error @ 1: 0.2887
  Num examples: 1500  Num correct: 1046  Error @ 1: 0.3027
  Num examples: 1500  Num correct: 990  Error @ 1: 0.3400
Step 10000: loss = 2.76 (0.127 sec)
  Num examples: 3000  Num correct: 2184  Error @ 1: 0.2720
  Num examples: 1500  Num correct: 1076  Error @ 1: 0.2827
  Num examples: 1500  Num correct: 1035  Error @ 1: 0.3100
Step 15000: loss = 2.69 (0.644 sec)
  Num examples: 3000  Num correct: 2215  Error @ 1: 0.2617
  Num examples: 1500  Num correct: 1091  Error @ 1: 0.2727
  Num examples: 1500  Num correct: 1058  Error @ 1: 0.2947
Step 20000: loss = 2.69 (0.127 sec)
  Num examples: 3000  Num correct: 2318  Error @ 1: 0.2273
  Num examples: 1500  Num correct: 1119  Error @ 1: 0.2540
  Num examples: 1500  Num correct: 1087  Error @ 1: 0.2753
Step 25000: loss = 2.66 (0.125 sec)
  Num examples: 3000  Num correct: 2271  Error @ 1: 0.2430
  Num examples: 1500  Num correct: 1122  Error @ 1: 0.2520
  Num examples: 1500  Num correct: 1082  Error @ 1: 0.2787
Step 30000: loss = 2.65 (0.638 sec)
  Num examples: 3000  Num correct: 2339  Error @ 1: 0.2203
  Num examples: 1500  Num correct: 1154  Error @ 1: 0.2307
  Num examples: 1500  Num correct: 1108  Error @ 1: 0.2613
Step 35000: loss = 2.63 (0.153 sec)
  Num examples: 3000  Num correct: 2373  Error @ 1: 0.2090
  Num examples: 1500  Num correct: 1177  Error @ 1: 0.2153
  Num examples: 1500  Num correct: 1132  Error @ 1: 0.2453
Step 40000: loss = 2.63 (0.128 sec)
  Num examples: 3000  Num correct: 2400  Error @ 1: 0.2000
  Num examples: 1500  Num correct: 1192  Error @ 1: 0.2053
  Num examples: 1500  Num correct: 1151  Error @ 1: 0.2327
Step 45000: loss = 2.65 (0.596 sec)
  Num examples: 3000  Num correct: 2393  Error @ 1: 0.2023
  Num examples: 1500  Num correct: 1195  Error @ 1: 0.2033
  Num examples: 1500  Num correct: 1153  Error @ 1: 0.2313
